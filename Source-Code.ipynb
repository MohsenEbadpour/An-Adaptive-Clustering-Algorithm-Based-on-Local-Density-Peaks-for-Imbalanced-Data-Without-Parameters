{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Big Data | Final Project\n",
    "### Mohsen Ebadpour | 400131080 | M.Ebadpour@aut.ac.ir \n",
    "#### Spring 2023 \n",
    "##### An Adaptive Clustering Algorithm Based on Local-Density Peaks for Imbalanced Data Without Parameters"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "--- \n",
    "## Importing libraries and packages "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import numpy as np \n",
    "import matplotlib.pyplot as plt \n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "import seaborn as sns \n",
    "import scipy.io\n",
    "import pandas as pd \n",
    "from tqdm import tqdm \n",
    "import networkx as nx\n",
    "from scipy import stats as st\n",
    "from sklearn.metrics import recall_score,accuracy_score,normalized_mutual_info_score,adjusted_mutual_info_score,confusion_matrix\n",
    "from sklearn import preprocessing\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.cluster import DBSCAN\n",
    "\n",
    "import time"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "--- \n",
    "## Loading datasets and pre-processing "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_dataset(name=\"banana.mat\"):\n",
    "    \"\"\"\n",
    "    Loads and preprocesses the dataset from the given file name.\n",
    "\n",
    "    Args:\n",
    "        name (str): The file name of the dataset to be loaded. Defaults to \"banana.mat\".\n",
    "\n",
    "    Returns:\n",
    "        X (np.ndarray): The feature matrix of the preprocessed dataset.\n",
    "        Y (np.ndarray): The target vector of the preprocessed dataset.\n",
    "    \"\"\"\n",
    "    name = \"./dataset/\" + name\n",
    "    if \"mat\" in name:\n",
    "        file = scipy.io.loadmat(name)\n",
    "        X,Y = file['data'],file[\"label\"]\n",
    "        \n",
    "        \n",
    "    \n",
    "    elif \"thyroid\" in name : \n",
    "        data_frame = pd.read_csv(name,header=None)\n",
    "        data = data_frame.to_numpy()\n",
    "        Y,X = data[:,0],data[:,1:]\n",
    "\n",
    "    elif \"sensor\" in name :\n",
    "        data_frame = pd.read_csv(name,header=None)\n",
    "        label_encoder = preprocessing.LabelEncoder()\n",
    "        data_frame[24]= label_encoder.fit_transform(data_frame[24])\n",
    "        data = data_frame.to_numpy()\n",
    "        Y,X = data[:,24],data[:,:24]\n",
    "        \n",
    "    elif \"ecoli\" in name :\n",
    "        data_frame = pd.read_csv(name,header=None)\n",
    "        label_encoder = preprocessing.LabelEncoder()\n",
    "        #data_frame.drop(0,axis=1,inplace=True)\n",
    "        data_frame[6]= label_encoder.fit_transform(data_frame[6])\n",
    "        \n",
    "        label_encoder = preprocessing.LabelEncoder()\n",
    "        data_frame[0]= label_encoder.fit_transform(data_frame[0])\n",
    "        \n",
    "        \n",
    "        data = data_frame.to_numpy()\n",
    "        Y,X = data[:,6],data[:,:6]\n",
    "    \n",
    "    \n",
    "    else :\n",
    "        data = pd.read_csv(name+\".arff.txt\",header=None)\n",
    "        Y = data[2].to_numpy() + 1\n",
    "        data.drop(2,axis=1,inplace=True)\n",
    "        X = data.to_numpy()\n",
    "    \n",
    "    # Normalize the feature matrix to eliminate the sensitivity to the range of distances.    \n",
    "    X = X/ X.max(axis=0)\n",
    "    return X,Y\n",
    "\n",
    "\n",
    "x_banana , y_banana = load_dataset()\n",
    "x_thyroid, y_thyroid = load_dataset(\"new-thyroid.data\")\n",
    "x_ids2, y_ids2 = load_dataset(\"ids2.mat\")\n",
    "x_lithuanian, y_lithuanian = load_dataset(\"lithuanian.mat\")\n",
    "x_sensor, y_sensor = load_dataset(\"sensor_readings_24.data\") \n",
    "x_guassian, y_guassian = load_dataset(\"gaussian.mat\") \n",
    "x_ecoli,y_ecoli = load_dataset(\"ecoli_new.data.csv\") \n",
    "\n",
    "x_t5,y_t5 = load_dataset(\"cluto-t5-8k\") \n",
    "x_t7,y_t7 = load_dataset(\"cluto-t7-10k\") \n",
    "x_zel,y_zel = load_dataset(\"zelnik4\") \n",
    "x_zel2,y_zel2 = load_dataset(\"zelnik2\") \n",
    "\n",
    "x_wingnut,y_wingnut = load_dataset(\"wingnut\") \n",
    "\n",
    "\n",
    "datasets = [(x_ecoli,y_ecoli),(x_thyroid, y_thyroid),(x_banana , y_banana),(x_sensor, y_sensor),(x_ids2, y_ids2),(x_lithuanian, y_lithuanian),\n",
    "            (x_t5,y_t5),(x_t7,y_t7),(x_guassian, y_guassian ),(x_zel,y_zel),(x_zel2,y_zel2),(x_wingnut,y_wingnut)]\n",
    "dataset_names = [\"Ecoli\",\"Thyroid\",\"Banana\",\"Robot navigation\",\"Ids2\",\"Lithuanian\",\"cluto-t5-8k\",\"cluto-t7-10k\",\"Guassian\",\"zelnik4\",\"zelnik2\",\"wingnut\"]\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Implementing Algorithm "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "def distance_measure (datapoint1, datapoint2 , metric = \"euclidean\") :\n",
    "    \"\"\"\n",
    "    Computes the distance between two given data points based on the specified distance metric.\n",
    "\n",
    "    Args:\n",
    "        datapoint1 (np.ndarray): The first data point.\n",
    "        datapoint2 (np.ndarray): The second data point.\n",
    "        metric (str): The distance metric to be used. Defaults to \"euclidean\".\n",
    "\n",
    "    Returns:\n",
    "        dist (float): The distance between the two data points based on the specified distance metric.\n",
    "    \"\"\"\n",
    "    dist = -1\n",
    "    if metric == \"euclidean\":\n",
    "        dist = np.linalg.norm(datapoint1 - datapoint2)\n",
    "    assert(dist!=-1)    \n",
    "    return dist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_dc(dataset):\n",
    "    \"\"\"\n",
    "    Computes the threshold distance (dc) and the distance matrix for the input dataset.\n",
    "\n",
    "    Args:\n",
    "        dataset (Tuple[np.ndarray, np.ndarray]): The input dataset as a tuple of feature matrix (X) and target vector (Y).\n",
    "\n",
    "    Returns:\n",
    "        dc (float): The threshold distance (dc) for the input dataset.\n",
    "        distance_mat (np.ndarray): The distance matrix for the input dataset.\n",
    "    \"\"\"\n",
    "    # Extract the feature matrix from the input dataset.\n",
    "    x,y = dataset \n",
    "    dc = -np.inf\n",
    "    distance_mat = np.zeros((x.shape[0],x.shape[0]))\n",
    "    \n",
    "    # Compute the distance matrix and the threshold distance (dc) for the input dataset.\n",
    "    for i in tqdm(range(x.shape[0])):\n",
    "        nearest_neighbor_distance = np.inf\n",
    "        for j in range(x.shape[0]):\n",
    "            # Keep track of the nearest neighbor distance for the i-th data point.\n",
    "            if i == j :\n",
    "                continue\n",
    "            \n",
    "            # Compute the distance between the i-th and j-th data points using the Euclidean distance metric.\n",
    "            dist = distance_measure(x[i],x[j])\n",
    "            distance_mat[i,j] = dist  \n",
    "            nearest_neighbor_distance = min(nearest_neighbor_distance,dist)\n",
    "            \n",
    "        # Update the threshold distance (dc) if the nearest neighbor distance for the i-th data point is larger.\n",
    "        dc = max(dc,nearest_neighbor_distance)\n",
    "    return dc,distance_mat \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_density(dataset,dc,dis_mat):\n",
    "    \"\"\"\n",
    "    Computes the density for each data point in the input dataset.\n",
    "\n",
    "    Args:\n",
    "        dataset (Tuple[np.ndarray, np.ndarray]): The input dataset as a tuple of feature matrix (X) and target vector (Y).\n",
    "        dc (float): The threshold distance (dc) for the input dataset.\n",
    "        dis_mat (np.ndarray): The distance matrix for the input dataset.\n",
    "\n",
    "    Returns:\n",
    "        densities (List[float]): The density for each data point in the input dataset.\n",
    "    \"\"\"\n",
    "    x,y = dataset \n",
    "    densities = []\n",
    "    \n",
    "    for i in range(x.shape[0]):\n",
    "        density = 0 \n",
    "        for j in range(x.shape[0]):\n",
    "            if i == j :\n",
    "                continue\n",
    "            dist = dis_mat[i,j]\n",
    "            if dist <= dc : \n",
    "                density += np.exp(-(dist/dc)**2)\n",
    "        densities.append(density)\n",
    "        \n",
    "    return densities\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_upward_distance(densities,dis_mat):\n",
    "    \"\"\"\n",
    "    Computes the upward distance for each data point in the input dataset.\n",
    "\n",
    "    Args:\n",
    "        densities (List[float]): The density for each data point in the input dataset.\n",
    "        dis_mat (np.ndarray): The distance matrix for the input dataset.\n",
    "\n",
    "    Returns:\n",
    "        up_dis (List[float]): The upward distance for each data point in the input dataset.\n",
    "    \"\"\"\n",
    "    up_dis = []\n",
    "    \n",
    "    for i in range(len(densities)):\n",
    "        max_up = - np.inf\n",
    "        min_up = +np.inf\n",
    "        is_greater_all = True\n",
    "        for j in range(len(densities)):\n",
    "            if i == j:\n",
    "                continue \n",
    "            \n",
    "            if densities[j] >= densities [i]:\n",
    "                is_greater_all = False \n",
    "            \n",
    "            max_up = max(max_up,dis_mat[i,j])\n",
    "            \n",
    "            if densities[j] > densities[i]:\n",
    "                min_up = min (min_up,dis_mat[i,j])\n",
    "                \n",
    "        if is_greater_all :\n",
    "            up_dis.append(max_up)\n",
    "        else:\n",
    "            up_dis.append(min_up)\n",
    "            \n",
    "    return up_dis\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_neighbors(dis_mat,K=None):\n",
    "    \"\"\"\n",
    "    Computes the K-nearest neighbors for each data point in the input dataset.\n",
    "\n",
    "    Args:\n",
    "        dis_mat (np.ndarray): The distance matrix for the input dataset.\n",
    "        K (Optional[int]): The number of nearest neighbors to consider. If None, defaults to the square root of the number of data points.\n",
    "\n",
    "    Returns:\n",
    "        neighbors (List[np.ndarray]): The K-nearest neighbors for each data point in the input dataset.\n",
    "        reverse_neighbors (List[List[int]]): The reverse nearest neighbors for each data point in the input dataset.\n",
    "    \"\"\"\n",
    "    if K is None:\n",
    "        K = int(np.sqrt(dis_mat.shape[0]))\n",
    "    neighbors =  []\n",
    "    reverse_neighbors = [[] for _ in range(dis_mat.shape[0])]\n",
    "    for i in range(dis_mat.shape[0]):\n",
    "        i_neighbors = np.argsort(dis_mat[i])[1:1+K]\n",
    "        neighbors.append(i_neighbors)\n",
    "        \n",
    "        for j in i_neighbors:\n",
    "            reverse_neighbors[j].append(i)    \n",
    "    return neighbors,reverse_neighbors\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "def determine_noise_and_init(up_dis,densities,reverse_neighbors,dis_mat):\n",
    "    \"\"\"\n",
    "    Determines the noise points and initializes the cluster centers for the input dataset.\n",
    "\n",
    "    Args:\n",
    "        up_dis (List[float]): The upward distances for each data point in the input dataset.\n",
    "        densities (List[float]): The density for each data point in the input dataset.\n",
    "        reverse_neighbors (List[List[int]]): The reverse nearest neighbors for each data point in the input dataset.\n",
    "        dis_mat (np.ndarray): The distance matrix for the input dataset.\n",
    "\n",
    "    Returns:\n",
    "        clusters (np.ndarray): The cluster labels for each data point in the input dataset.\n",
    "        sub_clusters_init (List[int]): The indices of the initial cluster centers.\n",
    "        ICC (int): The number of initial clusters.\n",
    "        noise_count (int): The number of noise points.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Compute the mean and standard deviation of the upward distances, densities, and reverse nearest neighbors.\n",
    "    up_dis_mean = np.mean(up_dis)\n",
    "    up_dis_std = np.std(up_dis)\n",
    "    \n",
    "    densities_mean = np.mean(densities)\n",
    "    densities_std = np.std(densities)\n",
    "    \n",
    "    rnn = list(map(len,reverse_neighbors))\n",
    "    \n",
    "    rnn_mean = np.mean(rnn)\n",
    "    rnn_std = np.std(rnn)\n",
    "    \n",
    "    clusters = np.ones((len(rnn)))*-1\n",
    "    sub_clusters_init = []\n",
    "    ICC = 0 \n",
    "    \n",
    "    #Determine the noise points based on the upward distance, reverse nearest neighbors, and density criteria.\n",
    "    j = 0 \n",
    "    noise_count = 0\n",
    "    for i in range(len(rnn)):\n",
    "        if up_dis[i] > up_dis_mean + up_dis_std and rnn[i] < rnn_mean - rnn_std and densities[i] < densities_mean - densities_std :\n",
    "            clusters[i] = 0\n",
    "            noise_count += 1\n",
    "    \n",
    "    # Determine the initial cluster centers based on the upward distance criteria.\n",
    "    for i in range(len(rnn)):\n",
    "        if up_dis[i] > up_dis_mean + up_dis_std and clusters[i] != 0 :\n",
    "            j += 1 \n",
    "            ICC += 1 \n",
    "            clusters[i] = j\n",
    "            sub_clusters_init.append(i)\n",
    "    \n",
    "    # Assign the remaining data points to their nearest cluster.\n",
    "    for i in np.argsort(np.array(densities)*(-1)):\n",
    "        if clusters[i] != -1:\n",
    "            continue\n",
    "        \n",
    "        nearest_neighbors = np.argsort(dis_mat[i])[1:]\n",
    "        for neighbor in nearest_neighbors:\n",
    "            if densities[neighbor] > densities[i] :\n",
    "                clusters[i] = clusters[neighbor]\n",
    "                if clusters[i] == -1 :\n",
    "                    raise ValueError(\"Non-Cluster label selected!\")\n",
    "                break\n",
    "            \n",
    "    return clusters,sub_clusters_init,ICC,noise_count\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_clusters(densities,clusters,dis_mat,sub_clusters_init,dc,ICC,improve=False):\n",
    "    \"\"\"\n",
    "    Updates the clusters by removing false positive sub-clusters and re-assigning their members to other clusters.\n",
    "\n",
    "    Args:\n",
    "        densities (List[float]): The density for each data point in the input dataset.\n",
    "        clusters (np.ndarray): The cluster labels for each data point in the input dataset.\n",
    "        dis_mat (np.ndarray): The distance matrix for the input dataset.\n",
    "        sub_clusters_init (List[int]): The indices of the initial cluster centers.\n",
    "        dc (float): The threshold distance for defining a cluster.\n",
    "        ICC (int): The number of initial clusters.\n",
    "\n",
    "    Returns:\n",
    "        clusters (np.ndarray): The updated cluster labels for each data point in the input dataset.\n",
    "        ICC (int): The updated number of clusters.\n",
    "        removed_sub_clusters (List[int]): The indices of the removed sub-clusters.\n",
    "    \"\"\"\n",
    "    # Remove false positive sub-clusters.\n",
    "    removed_sub_clusters = []\n",
    "    for cluster_index in sub_clusters_init:\n",
    "        n_total_members_in_clusters = np.where(clusters==clusters[cluster_index])[0].shape[0] \n",
    "        center_neighbor_distances = dis_mat[cluster_index]\n",
    "        n_radius_dc = np.where(center_neighbor_distances<=dc)[0].shape[0]\n",
    "        \n",
    "        if n_total_members_in_clusters < 0.5 * n_radius_dc :\n",
    "            if improve:\n",
    "                clusters[clusters==clusters[cluster_index]] = 0\n",
    "            else:\n",
    "                clusters[clusters==clusters[cluster_index]] = -1\n",
    "            ICC -= 1 \n",
    "            removed_sub_clusters.append(cluster_index)\n",
    "            \n",
    "    # Re-assign the remaining data points to their nearest cluster.        \n",
    "    for i in np.argsort(np.array(densities)*(-1)):\n",
    "        if clusters[i] != -1:\n",
    "            continue\n",
    "        nearest_neighbors = np.argsort(dis_mat[i])[1:]\n",
    "        for neighbor in nearest_neighbors:\n",
    "            if densities[neighbor] > densities[i] :\n",
    "                clusters[i] = clusters[neighbor]\n",
    "                \n",
    "                if clusters[i] == -1 :\n",
    "                    continue\n",
    "                break\n",
    "    return clusters, ICC,removed_sub_clusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clusters_distance(dis_mat,clusters_m_members,cluster_n_members):\n",
    "    \"\"\"\n",
    "    Computes the distance between two clusters.\n",
    "\n",
    "    Args:\n",
    "        dis_mat (np.ndarray): The distance matrix for the input dataset.\n",
    "        clusters_m_members (np.ndarray): The indices of the data points in cluster m.\n",
    "        cluster_n_members (np.ndarray): The indices of the data points in cluster n.\n",
    "\n",
    "    Returns:\n",
    "        Tuple[float, int, int]: The distance between the two clusters and the indices of the closest data points in the two clusters.\n",
    "    \"\"\"\n",
    "    distnaces = dis_mat[:,cluster_n_members][clusters_m_members,:]\n",
    "    min_value = distnaces.flatten().min()\n",
    "    i,j = np.where(distnaces==min_value)\n",
    "    i,j = i[0],j[0]\n",
    "    return distnaces.flatten().min(),clusters_m_members[i],cluster_n_members[j]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_In_set(_densities,cluster_members):\n",
    "    \"\"\"\n",
    "    Computes the set of inner points in a cluster.\n",
    "\n",
    "    Args:\n",
    "        _densities (np.ndarray): The density for each data point in the input dataset.\n",
    "        cluster_members (np.ndarray): The indices of the data points in the cluster.\n",
    "\n",
    "    Returns:\n",
    "        np.ndarray: The indices of the inner points in the cluster.\n",
    "    \"\"\"\n",
    "    boundary = []\n",
    "    _densities = np.array(_densities)\n",
    "    cluster_members = np.array(cluster_members)\n",
    "    avg_den = np.mean(_densities[cluster_members])\n",
    "    for member in cluster_members:\n",
    "        if _densities[member] < avg_den:\n",
    "            boundary.append(member)   \n",
    "    res = [i for i in cluster_members if not i in boundary]    \n",
    "    return np.array(res)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_merge_labels(pairs,i,j):\n",
    "    \"\"\"\n",
    "    Updates the merge labels dictionary.\n",
    "\n",
    "    Args:\n",
    "        pairs (Dict[int, List[int]]): The merge labels dictionary.\n",
    "        i (int): The index of the first cluster to be merged.\n",
    "        j (int): The index of the second cluster to be merged.\n",
    "\n",
    "    Returns:\n",
    "        Dict[int, List[int]]: The updated merge labels dictionary.\n",
    "    \"\"\"\n",
    "    i,j = int(i),int(j)\n",
    "    if not i in pairs :\n",
    "        pairs[i] = [j]\n",
    "    else:\n",
    "        pairs[i].append(j)\n",
    "    \n",
    "    if not j in pairs :\n",
    "        pairs[j] = [i]\n",
    "    else:\n",
    "        pairs[j].append(i)\n",
    "        \n",
    "    return pairs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def merging_clusters(dc,dis_mat,densities,clusters,sub_clusters_init,improve=False,dataset=None):\n",
    "    \"\"\"\n",
    "    Merge clusters based on the specified algorithm.\n",
    "\n",
    "    Parameters:\n",
    "    dc (float): Threshold distance for merging clusters.\n",
    "    dis_mat (array): Distance matrix between points.\n",
    "    densities (array): Density of each point.\n",
    "    clusters (array): Cluster label of each point.\n",
    "    sub_clusters_init (array): Initial centers of subclusters.\n",
    "\n",
    "    Returns:\n",
    "    clusters (array): Updated cluster labels for each point.\n",
    "    new_labels (list): List of merged subclusters.\n",
    "    \"\"\"\n",
    "    # Initialize current centers and label_centers\n",
    "    current_centers = []\n",
    "    label_centers = {}\n",
    "    for center in sub_clusters_init:\n",
    "        current_centers.append(center)\n",
    "        label_centers[clusters[center]] = center\n",
    "    \n",
    "    # Calculate the radius of merging\n",
    "    n_noise = np.where(clusters==0)[0].shape[0]\n",
    "    if n_noise == 0 :\n",
    "        r = dc \n",
    "    else:\n",
    "        _dis_mat = dis_mat.copy()\n",
    "        for _ in range(len(clusters)):\n",
    "            _dis_mat[_,_] = np.inf\n",
    "        _dis_mat = np.delete(_dis_mat, np.where(clusters==0)[0] , 0)\n",
    "        _dis_mat = np.delete(_dis_mat, np.where(clusters==0)[0] , 1)\n",
    "        r = np.max(np.min(_dis_mat,axis=0))\n",
    "\n",
    "    # Get unique cluster labels\n",
    "    clusters_labels = np.unique(clusters)\n",
    "    clusters_labels = np.delete(clusters_labels,np.where(clusters_labels==0))\n",
    "    densities = np.array(densities)\n",
    "    \n",
    "    # Initialize merge_pairs dictionary\n",
    "    merge_pairs = {}\n",
    "    \n",
    "    # Loop through all possible cluster pairs\n",
    "    for cluster_m in range(clusters_labels.shape[0]-1):\n",
    "        cluster_m_members = np.where(clusters==clusters_labels[cluster_m])[0]\n",
    "        m_in = get_In_set(densities,cluster_m_members)\n",
    "        \n",
    "        for cluster_n in range(cluster_m+1,clusters_labels.shape[0]):\n",
    "            cluster_n_members = np.where(clusters==clusters_labels[cluster_n])[0]\n",
    "            n_in = get_In_set(densities,cluster_n_members)\n",
    "            \n",
    "            n_m_distnace,i,j = clusters_distance(dis_mat,cluster_m_members,cluster_n_members)\n",
    "            \n",
    "            density_m_center = densities[label_centers[clusters_labels[cluster_m]]]\n",
    "            density_n_center = densities[label_centers[clusters_labels[cluster_n]]]\n",
    "        \n",
    "            # Merge the clusters if the conditions are met\n",
    "            if n_m_distnace < r :\n",
    "                if i in m_in and j in n_in:\n",
    "                    merge_pairs = update_merge_labels(merge_pairs,clusters_labels[cluster_m],clusters_labels[cluster_n])\n",
    "                    \n",
    "                elif densities[i] + densities[j] > np.mean([density_m_center,density_n_center]):\n",
    "                    merge_pairs = update_merge_labels(merge_pairs,clusters_labels[cluster_m],clusters_labels[cluster_n])\n",
    "                    \n",
    "    # Construct a graph and get the connected components\n",
    "    graph = nx.Graph(merge_pairs)\n",
    "    new_labels = list(map(list,list(nx.connected_components(graph))))\n",
    "    \n",
    "    # Update cluster labels for each point\n",
    "    for idx in range(len(new_labels)):\n",
    "        for cluster_label in new_labels[idx] :\n",
    "            clusters[clusters==cluster_label] = int(idx + 1)\n",
    "    \n",
    "    \n",
    "    if improve:     \n",
    "        x,y = dataset\n",
    "        noise_index =  np.where(clusters==0)[0]\n",
    "        x_noise,y_noise = x[noise_index],y[noise_index]\n",
    "        clusters_members_count = []\n",
    "        for label in np.unique(clusters):\n",
    "            clusters_members_count.append(np.where(clusters==label)[0].shape[0])\n",
    "        \n",
    "        clusters_members_count.sort()\n",
    "        _min = int(np.mean(clusters_members_count[:len(clusters_members_count)*3//4])/2)+1  \n",
    "        \n",
    "        clustering_db = DBSCAN(eps=dc, min_samples=_min).fit(x_noise) \n",
    "        noise_labels = clustering_db.labels_ \n",
    "        \n",
    "        clusters[noise_index[noise_labels != -1]] = 0 \n",
    "        clusters[noise_index[noise_labels == -1]] = -1\n",
    "        \n",
    "        \n",
    "    # Assign noisy points to the nearest cluster        \n",
    "    for i in np.argsort(np.array(densities)*(-1)):\n",
    "        if clusters[i] != 0:\n",
    "            continue\n",
    "        \n",
    "        nearest_neighbors = np.argsort(dis_mat[i])[1:]\n",
    "        for neighbor in nearest_neighbors:\n",
    "            if densities[neighbor] > densities[i]:\n",
    "                clusters[i] = clusters[neighbor]\n",
    "                \n",
    "                if clusters[i] == -1 and not(improve):\n",
    "                    continue\n",
    "                break\n",
    "                \n",
    "    clusters = clusters - 1\n",
    "    \n",
    "    return clusters,new_labels, merge_pairs \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prediction_report(clusters,true_labels,improve=False,densities=None,up_dis=None):\n",
    "    \"\"\"\n",
    "    Returns necessary evaluation metrics and results.\n",
    "\n",
    "    Parameters:\n",
    "    clusters (array): Cluster labels for each point.\n",
    "    true_labels (array): Ground truth labels for each point.\n",
    "\n",
    "    Returns:\n",
    "    acc (float): Accuracy score.\n",
    "    recall (float): Recall score.\n",
    "    nmi (float): Normalized mutual information score.\n",
    "    cm (array): Confusion matrix.\n",
    "    clusters (array): Updated cluster labels for each point.\n",
    "    prediction_rule (dict): Mapping of initial labels to new cluster labels.\n",
    "    \"\"\"\n",
    "    \n",
    "    prediction_rule = {}\n",
    "    for label in np.unique(clusters):\n",
    "        if improve : \n",
    "            densities,up_dis = np.array(densities),np.array(up_dis)\n",
    "            if densities[clusters==label].max(axis=0) != 0:\n",
    "                new_den = densities[clusters==label]/ densities[clusters==label].max(axis=0)  \n",
    "                \n",
    "            weight = true_labels[clusters==label] *  new_den  \n",
    "            weighted_mean = np.mean(weight)\n",
    "            \n",
    "            orginal_labels = np.unique(true_labels)\n",
    "            new_label_index = np.argmin(np.sqrt((orginal_labels - weighted_mean)**2))\n",
    "            prediction_rule[-label] = orginal_labels[new_label_index] \n",
    "        \n",
    "        else:\n",
    "            # Find the mode of true_labels for each cluster\n",
    "            _mode = st.mode(true_labels[clusters==label],keepdims=False)\n",
    "            prediction_rule[-label] = int(_mode[0])\n",
    "\n",
    "    # Update cluster labels using prediction_rule\n",
    "    clusters = clusters * (-1)\n",
    "    for label in np.unique(clusters):\n",
    "        clusters[clusters==label] = prediction_rule[label]\n",
    "        \n",
    "    # Calculate evaluation metrics using updated labels\n",
    "    acc = accuracy_score(true_labels,clusters)\n",
    "    recall = recall_score(true_labels,clusters,average='macro')\n",
    "    nmi = normalized_mutual_info_score(true_labels,clusters)\n",
    "    cm = confusion_matrix(true_labels,clusters)\n",
    "    return acc,recall,nmi,cm,clusters,prediction_rule\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "def report_results(name,dataset,new_clusters,densities,up_dis,reverse_neighbors,clusters,Noise,K_acc,cm,K_recall,K_nmi,K_time):\n",
    "        _name = name + \" | \"\n",
    "        plt.rcParams[\"figure.figsize\"] = 16,16\n",
    "        sns.set_style(\"whitegrid\")\n",
    "        x,y = dataset\n",
    "        f1,f2 = \"Feature-1\",\"Feature-2\"\n",
    "        if x.shape[1] != 2 :\n",
    "                pca = PCA(n_components=2)\n",
    "                x = pca.fit_transform(x)\n",
    "                f1,f2 = \"Components-1(PCA)\",\"Components-2(PCA)\"\n",
    "                \n",
    "        data = {f1:x.T[0],f2:x.T[1],\"Label\":y.flatten(),\n",
    "                \"Clustering Result\":new_clusters,\"Densities\":densities,\"upward distances\":up_dis,\n",
    "                \"RNN\":list(map(len,reverse_neighbors)), \"Initialized sub-clusters\":clusters}\n",
    "\n",
    "        H,W,I = 3,3,1\n",
    "        plt.subplot(H,W,I)\n",
    "        I+=1\n",
    "        sns.scatterplot(data=data,x=f1,y=f2,hue=\"Label\")\n",
    "        plt.title(_name+\"Orginal Dataset | Count of labels:{0}\".format(np.unique(y.flatten()).shape[0]))\n",
    "\n",
    "        plt.subplot(H,W,I)\n",
    "        I+=1\n",
    "        sns.scatterplot(data=data,x=\"Densities\",y=\"upward distances\",hue=\"Label\")\n",
    "        plt.title(_name+\"2D Decision Graph\")\n",
    "\n",
    "        plt.subplot(H,W,I)\n",
    "        I+=1\n",
    "        sns.scatterplot(data=data,x=f1,y=f2,hue=\"Initialized sub-clusters\")\n",
    "        plt.title(\"Initialized sub-clusters after updating\")\n",
    "\n",
    "        plt.subplot(H,W,I)\n",
    "        I+=1\n",
    "        sns.scatterplot(data=data,x=f1,y=f2,hue=\"Clustering Result\")\n",
    "        plt.title(\"Clustering Result | Count of Clusters:{0}\".format(np.unique(new_clusters.flatten()).shape[0]))\n",
    "\n",
    "        plt.subplot(H,W,I)\n",
    "        I+=1\n",
    "        plt.plot(Ks,Noise,color=\"black\")\n",
    "        plt.title(_name+\"Counts of noisy points in NN calculating\")\n",
    "        plt.xlabel(\"K\")\n",
    "        plt.ylabel(\"# Noisy points\")\n",
    "        \n",
    "        plt.subplot(H,W,I)\n",
    "        I+=1\n",
    "        plt.plot(Ks,K_time,color=\"orange\")\n",
    "        plt.title(_name+\"Run-Time in sec. in NN calculating\")\n",
    "        plt.xlabel(\"K\")\n",
    "        plt.ylabel(\"Run-Time in sec.\")\n",
    "\n",
    "        plt.subplot(H,W,I)\n",
    "        I+=1\n",
    "        plt.plot(Ks,K_acc,color=\"green\")\n",
    "        plt.title(_name+\"Accuracy in NN calculating | max:{0}\".format(round(max(K_acc)*100,2)))\n",
    "        plt.xlabel(\"K\")\n",
    "        plt.ylabel(\"Accuracy\")\n",
    "\n",
    "        plt.subplot(H,W,I)\n",
    "        I+=1\n",
    "        plt.plot(Ks,K_recall,color=\"blue\")\n",
    "        plt.title(_name+\"Recall in NN calculating | max:{0}\".format(round(max(K_recall)*100,2)))\n",
    "        plt.xlabel(\"K\")\n",
    "        plt.ylabel(\"Recall\")\n",
    "\n",
    "\n",
    "        plt.subplot(H,W,I)\n",
    "        I+=1\n",
    "        plt.plot(Ks,K_nmi,color=\"magenta\")\n",
    "        plt.title(_name+\"NMI in NN calculating | max:{0}\".format(round(max(K_nmi)*100,2)))\n",
    "        plt.xlabel(\"K\")\n",
    "        plt.ylabel(\"NMI\")\n",
    "\n",
    "\n",
    "        plt.legend()\n",
    "        plt.tight_layout()\n",
    "        plt.savefig(name+\".png\")\n",
    "        plt.show()\n",
    "        "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Reporting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = datasets[-1]\n",
    "name = dataset_names[-1]\n",
    "K_acc,K_recall,K_nmi,Noise = [],[],[],[]\n",
    "dc, dis_mat = calculate_dc(dataset)\n",
    "densities = calculate_density(dataset,dc,dis_mat.copy()) \n",
    "up_dis = calculate_upward_distance(densities.copy(),dis_mat.copy())  \n",
    "\n",
    "plt.rcParams[\"figure.figsize\"] = 4,4\n",
    "neighbors,reverse_neighbors = calculate_neighbors(dis_mat.copy())\n",
    "clusters,sub_clusters_init,ICC,noise_count = determine_noise_and_init(up_dis.copy(),densities.copy(),reverse_neighbors.copy(),dis_mat.copy())\n",
    "clusters,ICC,removed_sub_clusters = update_clusters(densities.copy(),clusters.copy(),dis_mat.copy(),sub_clusters_init.copy(),dc,ICC)\n",
    "new_clusters,new_labels,mp = merging_clusters(dc,dis_mat.copy(),densities.copy(),clusters.copy(),sub_clusters_init.copy())\n",
    "\n",
    "graph = nx.Graph(mp)\n",
    "nx.draw_spring(graph,with_labels=True,node_size=700,node_color=\"cyan\",node_shape=\"*\",\n",
    "               font_size=9,alpha=0.85,linewidths=0.75,edge_color=\"green\",style=\"--\")\n",
    "plt.title(\"Merging Sub-Clusters Graph | Lithuanian\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for d_index in range(len(datasets)):\n",
    "    s_time = time.time()\n",
    "    dataset = datasets[d_index]\n",
    "    name = dataset_names[d_index]\n",
    "    K_acc,K_recall,K_nmi,Noise = [],[],[],[]\n",
    "    dc, dis_mat = calculate_dc(dataset)\n",
    "    densities = calculate_density(dataset,dc,dis_mat.copy()) \n",
    "    up_dis = calculate_upward_distance(densities.copy(),dis_mat.copy())  \n",
    "    Ks,K_cm = [], []\n",
    "    K_time = []\n",
    "    pure_time = time.time() - s_time\n",
    "    densities_,sub_clusters_init_,up_dis_, new_clusters_,rnn_,prediction_rule_ = [],[],[],[],[],[]\n",
    "    \n",
    "    for k in tqdm(range(int(np.sqrt(dataset[0].shape[0])*.1+1),int(np.sqrt(dataset[0].shape[0])*1.9+1))):\n",
    "        s_time = time.time()\n",
    "        neighbors,reverse_neighbors = calculate_neighbors(dis_mat.copy(),k)\n",
    "        clusters,sub_clusters_init,ICC,noise_count = determine_noise_and_init(up_dis.copy(),densities.copy(),reverse_neighbors.copy(),dis_mat.copy())\n",
    "        clusters,ICC,removed_sub_clusters = update_clusters(densities.copy(),clusters.copy(),dis_mat.copy(),sub_clusters_init.copy(),dc,ICC)\n",
    "        new_clusters,new_labels,_ = merging_clusters(dc,dis_mat.copy(),densities.copy(),clusters.copy(),sub_clusters_init.copy())\n",
    "        x,y = dataset\n",
    "        acc,recall,nmi,cm,new_clusters,prediction_rule = prediction_report(new_clusters.copy(),y.flatten())\n",
    "        e_time = time.time() - s_time\n",
    "        \n",
    "        Ks.append(k)\n",
    "        K_acc.append(acc)\n",
    "        K_recall.append(recall)\n",
    "        K_nmi.append(nmi)\n",
    "        K_cm.append(cm)\n",
    "        Noise.append(noise_count)\n",
    "        \n",
    "        densities_.append(densities)\n",
    "        sub_clusters_init_.append(clusters)\n",
    "        up_dis_.append(up_dis)\n",
    "        new_clusters_.append(new_clusters)\n",
    "        rnn_.append(reverse_neighbors)\n",
    "        prediction_rule_.append(prediction_rule)\n",
    "        K_time.append(e_time+pure_time)\n",
    "    \n",
    "    i = K_acc.index(max(K_acc))\n",
    "    print(name,\",\",K_acc[i],\",\",K_recall[i],\",\",K_nmi[i],\",\",Noise[i],\",\",K_time[i],\",\",np.unique(new_clusters.flatten()).shape[0],\",\",np.unique(y.flatten()).shape[0],\",\\n\",K_cm[i].tolist())\n",
    "    densities,sub_clusters_init,up_dis, new_clusters,rnn,prediction_rule,cm = densities_[i],sub_clusters_init_[i],up_dis_[i], new_clusters_[i],rnn_[i],prediction_rule_[i],K_cm[i]\n",
    "    report_results(name,dataset,new_clusters,densities,up_dis,reverse_neighbors,clusters,Noise,K_acc,cm,K_recall,K_nmi,K_time) \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "_data = [\n",
    "    [\"Thyroid\" , 0.7302325581395349 , 0.41111111111111115 , 0.14035025233770546 , 2 , 0.3879883289337158 , 2 , 3 ],\n",
    "    [\"Guassian\" , 0.9895 , 0.9925708479938904 , 0.9370663518366252 , 54 , 33.21497678756714 , 4 , 4 ],\n",
    "    [\"Ids2\" , 0.9959375 , 0.9983000000000001 , 0.9778326514951051 , 43 , 74.87539029121399 , 5 , 5],\n",
    "    [\"Banana\" , 1.0 , 1.0 , 1.0 , 16 , 39.93293499946594 , 2 , 2 ],\n",
    "    [\"Lithuanian\" , 1.0 , 1.0 , 1.0 , 2 , 42.26874780654907 , 2 , 2 ]\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Dataset</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Recall</th>\n",
       "      <th>NMI</th>\n",
       "      <th># Noises</th>\n",
       "      <th>Run-Time sec.</th>\n",
       "      <th># Clusters</th>\n",
       "      <th># Labels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Thyroid</td>\n",
       "      <td>0.73023</td>\n",
       "      <td>0.41111</td>\n",
       "      <td>0.14035</td>\n",
       "      <td>2</td>\n",
       "      <td>0.38799</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Guassian</td>\n",
       "      <td>0.98950</td>\n",
       "      <td>0.99257</td>\n",
       "      <td>0.93707</td>\n",
       "      <td>54</td>\n",
       "      <td>33.21498</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Ids2</td>\n",
       "      <td>0.99594</td>\n",
       "      <td>0.99830</td>\n",
       "      <td>0.97783</td>\n",
       "      <td>43</td>\n",
       "      <td>74.87539</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Banana</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>16</td>\n",
       "      <td>39.93293</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Lithuanian</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>2</td>\n",
       "      <td>42.26875</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Dataset  Accuracy   Recall      NMI  # Noises  Run-Time sec.  \\\n",
       "0     Thyroid   0.73023  0.41111  0.14035         2        0.38799   \n",
       "1    Guassian   0.98950  0.99257  0.93707        54       33.21498   \n",
       "2        Ids2   0.99594  0.99830  0.97783        43       74.87539   \n",
       "3      Banana   1.00000  1.00000  1.00000        16       39.93293   \n",
       "4  Lithuanian   1.00000  1.00000  1.00000         2       42.26875   \n",
       "\n",
       "   # Clusters  # Labels  \n",
       "0           2         3  \n",
       "1           4         4  \n",
       "2           5         5  \n",
       "3           2         2  \n",
       "4           2         2  "
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame(_data,columns=[\"Dataset\",\"Accuracy\",\"Recall\",\"NMI\",\"# Noises\",\"Run-Time sec.\",\"# Clusters\",\"# Labels\"])\n",
    "df[\"Accuracy\"] = np.array(np.round(df[\"Accuracy\"],decimals=5))\n",
    "df[\"Recall\"] = np.array(np.round(df[\"Recall\"],decimals=5))\n",
    "df[\"NMI\"] = np.array(np.round(df[\"NMI\"],decimals=5))\n",
    "df[\"Run-Time sec.\"] = np.array(np.round(df[\"Run-Time sec.\"],decimals=5))\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "--- \n",
    "## Test to improve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Thyroid\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 215/215 [00:00<00:00, 681.54it/s]\n"
     ]
    }
   ],
   "source": [
    "data_for_tabel = []\n",
    "for d_index in range(len(datasets)):\n",
    "    dataset = datasets[d_index]\n",
    "    name = dataset_names[d_index]\n",
    "    if \"Robot\" in name:\n",
    "        continue\n",
    "    if not \"hyroid\" in name:\n",
    "        continue\n",
    "    print(name)\n",
    "    \n",
    "    \n",
    "    dc, dis_mat = calculate_dc(dataset)\n",
    "    densities = calculate_density(dataset,dc,dis_mat.copy()) \n",
    "    up_dis = calculate_upward_distance(densities.copy(),dis_mat.copy())  \n",
    "    \n",
    "    for improved_v in [False,True]:\n",
    "        neighbors,reverse_neighbors = calculate_neighbors(dis_mat.copy())\n",
    "        clusters,sub_clusters_init,ICC,noise_count = determine_noise_and_init(up_dis.copy(),densities.copy(),reverse_neighbors.copy(),dis_mat.copy())\n",
    "        clusters,ICC,removed_sub_clusters = update_clusters(densities.copy(),clusters.copy(),dis_mat.copy(),sub_clusters_init.copy(),dc,ICC,improved_v)\n",
    "        new_clusters,new_labels,_ = merging_clusters(dc,dis_mat.copy(),densities.copy(),clusters.copy(),sub_clusters_init.copy(),improved_v,dataset)\n",
    "        x,y = dataset\n",
    "        acc,recall,nmi,cm,new_clusters,prediction_rule = prediction_report(new_clusters.copy(),y.flatten())\n",
    "        data_for_tabel.append([name,acc,recall,nmi,noise_count,np.unique(new_clusters.flatten()).shape[0],np.unique(y.flatten()).shape[0],improved_v])\n",
    "    #print(data_for_tabel[-2:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "_data = [\n",
    " ['zelnik2',0.4158415841584158,0.40880503144654085,0.13052873776644158,12,2,3,False],\n",
    " ['zelnik2',0.6204620462046204,0.6037735849056604,0.5696819704451567,12,2,3,True],\n",
    " ['zelnik4', 0.6028938906752411, 0.6, 0.6264247616951141, 36, 3, 5, False],\n",
    " ['zelnik4',0.7491961414790996,0.7391304347826086,0.7981916278116126,36,4,5,True],\n",
    " ['Guassian', 0.9895, 0.9925708479938904, 0.9370663518366252, 53, 4, 4, False],\n",
    " ['Guassian', 0.9735, 0.9495750897742531, 0.8687188780003052, 53, 4, 4, True],\n",
    " ['cluto-t5-8k',0.3935,0.383812520628441,0.39979451986024084,242,4,7,False],\n",
    " ['cluto-t5-8k',0.7945,0.7841950588633025,0.828358769688396,242,6,7,True],\n",
    " ['Lithuanian', 1.0, 1.0, 1.0, 2, 2, 2, False],\n",
    " ['Lithuanian', 1.0, 1.0, 1.0, 2, 2, 2, True],\n",
    " ['Ids2', 0.9959375, 0.9983000000000001, 0.9778326514951051, 72, 5, 5, False],\n",
    " ['Ids2', 0.9346875, 0.7944000000000001, 0.8823302434257392, 72, 4, 5, True],\n",
    " ['Thyroid', 0.7302325581395349 , 0.41111111111111115 , 0.14035025233770546, 10, 2, 3, False],\n",
    " ['Thyroid', 0.7906976744186046,0.5555555555555555,0.3786734240581399,10,2,3,True],\n",
    " ['Banana', 1.0, 1.0, 1.0, 12, 2, 2, False],\n",
    " ['Banana', 0.9983333333333333, 0.999, 0.9763520059077306, 12, 2, 2, True]\n",
    " ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Dataset</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Recall</th>\n",
       "      <th>NMI</th>\n",
       "      <th># Noises</th>\n",
       "      <th># Clusters</th>\n",
       "      <th># Labels</th>\n",
       "      <th>Improved Version</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>zelnik2</td>\n",
       "      <td>0.41584</td>\n",
       "      <td>0.40881</td>\n",
       "      <td>0.13053</td>\n",
       "      <td>12</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>zelnik2</td>\n",
       "      <td>0.62046</td>\n",
       "      <td>0.60377</td>\n",
       "      <td>0.56968</td>\n",
       "      <td>12</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>zelnik4</td>\n",
       "      <td>0.60289</td>\n",
       "      <td>0.60000</td>\n",
       "      <td>0.62642</td>\n",
       "      <td>36</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>zelnik4</td>\n",
       "      <td>0.74920</td>\n",
       "      <td>0.73913</td>\n",
       "      <td>0.79819</td>\n",
       "      <td>36</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Guassian</td>\n",
       "      <td>0.98950</td>\n",
       "      <td>0.99257</td>\n",
       "      <td>0.93707</td>\n",
       "      <td>53</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Guassian</td>\n",
       "      <td>0.97350</td>\n",
       "      <td>0.94958</td>\n",
       "      <td>0.86872</td>\n",
       "      <td>53</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>cluto-t5-8k</td>\n",
       "      <td>0.39350</td>\n",
       "      <td>0.38381</td>\n",
       "      <td>0.39979</td>\n",
       "      <td>242</td>\n",
       "      <td>4</td>\n",
       "      <td>7</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>cluto-t5-8k</td>\n",
       "      <td>0.79450</td>\n",
       "      <td>0.78420</td>\n",
       "      <td>0.82836</td>\n",
       "      <td>242</td>\n",
       "      <td>6</td>\n",
       "      <td>7</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Lithuanian</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Lithuanian</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Ids2</td>\n",
       "      <td>0.99594</td>\n",
       "      <td>0.99830</td>\n",
       "      <td>0.97783</td>\n",
       "      <td>72</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Ids2</td>\n",
       "      <td>0.93469</td>\n",
       "      <td>0.79440</td>\n",
       "      <td>0.88233</td>\n",
       "      <td>72</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Thyroid</td>\n",
       "      <td>0.73023</td>\n",
       "      <td>0.41111</td>\n",
       "      <td>0.14035</td>\n",
       "      <td>10</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Thyroid</td>\n",
       "      <td>0.79070</td>\n",
       "      <td>0.55556</td>\n",
       "      <td>0.37867</td>\n",
       "      <td>10</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Banana</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>12</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Banana</td>\n",
       "      <td>0.99833</td>\n",
       "      <td>0.99900</td>\n",
       "      <td>0.97635</td>\n",
       "      <td>12</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Dataset  Accuracy   Recall      NMI  # Noises  # Clusters  # Labels  \\\n",
       "0       zelnik2   0.41584  0.40881  0.13053        12           2         3   \n",
       "1       zelnik2   0.62046  0.60377  0.56968        12           2         3   \n",
       "2       zelnik4   0.60289  0.60000  0.62642        36           3         5   \n",
       "3       zelnik4   0.74920  0.73913  0.79819        36           4         5   \n",
       "4      Guassian   0.98950  0.99257  0.93707        53           4         4   \n",
       "5      Guassian   0.97350  0.94958  0.86872        53           4         4   \n",
       "6   cluto-t5-8k   0.39350  0.38381  0.39979       242           4         7   \n",
       "7   cluto-t5-8k   0.79450  0.78420  0.82836       242           6         7   \n",
       "8    Lithuanian   1.00000  1.00000  1.00000         2           2         2   \n",
       "9    Lithuanian   1.00000  1.00000  1.00000         2           2         2   \n",
       "10         Ids2   0.99594  0.99830  0.97783        72           5         5   \n",
       "11         Ids2   0.93469  0.79440  0.88233        72           4         5   \n",
       "12      Thyroid   0.73023  0.41111  0.14035        10           2         3   \n",
       "13      Thyroid   0.79070  0.55556  0.37867        10           2         3   \n",
       "14       Banana   1.00000  1.00000  1.00000        12           2         2   \n",
       "15       Banana   0.99833  0.99900  0.97635        12           2         2   \n",
       "\n",
       "    Improved Version  \n",
       "0              False  \n",
       "1               True  \n",
       "2              False  \n",
       "3               True  \n",
       "4              False  \n",
       "5               True  \n",
       "6              False  \n",
       "7               True  \n",
       "8              False  \n",
       "9               True  \n",
       "10             False  \n",
       "11              True  \n",
       "12             False  \n",
       "13              True  \n",
       "14             False  \n",
       "15              True  "
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame(_data,columns=[\"Dataset\",\"Accuracy\",\"Recall\",\"NMI\",\"# Noises\",\"# Clusters\",\"# Labels\",\"Improved Version\"])\n",
    "df[\"Accuracy\"] = np.array(np.round(df[\"Accuracy\"],decimals=5))\n",
    "df[\"Recall\"] = np.array(np.round(df[\"Recall\"],decimals=5))\n",
    "df[\"NMI\"] = np.array(np.round(df[\"NMI\"],decimals=5))\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "ef0419ab323279f897e0eed305249e497fbac22342d2d07e01a7b8f24ca3f181"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
